import streamlit as st
import requests
import json
import re
import difflib
from unidecode import unidecode

# ======================================
# üîß UTILITIES
# ======================================

def normalize_string(text):
    """Chu·∫©n h√≥a chu·ªói: vi·∫øt th∆∞·ªùng, b·ªè d·∫•u, x√≥a k√Ω t·ª± ƒë·∫∑c bi·ªát."""
    if not text:
        return ""
    text = text.lower().strip()
    text = unidecode(text)
    text = text.replace("‚Äì", " ").replace("-", " ")
    text = re.sub(r"[^a-z0-9\s]", "", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()


def fuzzy_match(user_input, normalized_lookup, threshold=0.45):
    """T√¨m ƒë·ªãa ƒëi·ªÉm g·∫ßn ƒë√∫ng nh·∫•t theo fuzzy."""
    query = normalize_string(user_input)
    all_keys = list(normalized_lookup.keys())

    match = difflib.get_close_matches(query, all_keys, n=1, cutoff=threshold)
    if match:
        normalized_key = match[0]
        return normalized_lookup[normalized_key], difflib.SequenceMatcher(None, query, normalized_key).ratio()
    return None, 0.0


def detect_intent(text):
    """Nh·∫≠n di·ªán c√¢u m·ªõi hay follow-up."""
    text = text.lower().strip()

    follow_words = ["ti·∫øp", "n·ªØa", "ok", "oke", "r·ªìi sao", "sao n·ªØa", "ti·∫øp t·ª•c", "v·∫≠y"]
    if len(text.split()) <= 2:
        return "follow_up"
    if any(w in text for w in follow_words):
        return "follow_up"
    if "?" in text:
        return "new_question"
    return "new_question"

def detect_place_suggestion(text):
    text = normalize_string(text)

    keywords = [
        "di dau", "choi gi", "goi y", "noi nao", "dia diem",
        "cho vui", "cho nao thu vi", "nen di dau", "co gi vui",
        "dia diem du lich", "travel", "tham quan","di dau o tay ninh"
    ]

    return any(k in text for k in keywords)



# ======================================
# üçú DATABASE QU√ÅN ƒÇN
# ======================================

food_spots = {
    "n√∫i b√† ƒëen": [
        ("B√°nh canh Tr·∫£ng B√†ng B√© NƒÉm", "ƒë·∫∑c s·∫£n Tr·∫£ng B√†ng"),
        ("Qu√°n G√† H·∫•p H√†nh 7 N√∫i", "ƒë·∫∑c s·∫£n g√† h·∫•p"),
    ],
    "h·ªì d·∫ßu ti·∫øng": [
        ("H·∫£i S·∫£n T∆∞∆°i S·ªëng H·ªØu L·ª£i", "t√¥m c√° h·ªì r·∫•t t∆∞∆°i"),
        ("Qu√°n L·ªôc V·ª´ng", "view ng·∫Øm ho√†ng h√¥n"),
    ],
    "t√≤a th√°nh cao ƒë√†i": [
        ("B√∫n ri√™u B√† T√°m", "gi√° r·∫ª, ngon"),
        ("C∆°m chay T√¢m ƒê·ª©c", "qu√°n chay g·∫ßn nh·∫•t"),
    ],
    "l√†ng n·ªïi t√¢n l·∫≠p": [
        ("c√° l√≥c n∆∞·ªõng trui", "ngon qu√™n l·ªëi v·ªÅ"),
        ("b√°nh x√®o", "gi√≤n r·ª•m,ngon, tr·∫£i nghi·ªám kh√≥ qu√™n"),
    ],
}


# ======================================
# üìö T·∫¢I D·ªÆ LI·ªÜU TXT
# ======================================

DATA_FILE = "data_tayninh.txt"
IMAGES_FILE = "images.json"

try:
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        raw_text = f.read()
except:
    raw_text = ""
    st.error("‚ùå Kh√¥ng t√¨m th·∫•y file data_tayninh.txt")

tourism_data = {}
normalized_lookup = {}

current_key = None
for line in raw_text.splitlines():
    if line.startswith("###"):
        place = line.replace("###", "").strip().lower()
        tourism_data[place] = ""
        normalized_lookup[normalize_string(place)] = place
        current_key = place
    elif current_key:
        tourism_data[current_key] += line + "\n"


# ======================================
# üñº ·∫¢NH
# ======================================

try:
    with open(IMAGES_FILE, "r", encoding="utf-8") as f:
        images = json.load(f)
except:
    images = {}
    st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y images.json ho·∫∑c l·ªói ƒë·ªãnh d·∫°ng.")


# ======================================
# üåê GIAO DI·ªÜN STREAMLIT
# ======================================

st.set_page_config(page_title="Chatbot Du L·ªãch T√¢y Ninh", page_icon="üó∫Ô∏è")
st.title("üó∫Ô∏è Chatbot Du L·ªãch T√¢y Ninh ‚Äì Beta Version")
st.caption("Made by ƒêƒÉng Khoa üî∞ - 1.0")



# Session
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Xin ch√†o! B·∫°n mu·ªën kh√°m ph√° ƒë·ªãa ƒëi·ªÉm n√†o ·ªü T√¢y Ninh h√¥m nay?"}
    ]

if "topic" not in st.session_state:
    st.session_state.topic = None


# HI·ªÉn th·ªã l·ªãch s·ª≠ chat
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])


# ======================================
# ‚å®Ô∏è NH·∫¨N INPUT
# ======================================

user_input = st.chat_input("Nh·∫≠p c√¢u h·ªèi...")

if user_input:

    # Hi·ªÉn th·ªã c√¢u ng∆∞·ªùi d√πng
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # Intent
    intent = detect_intent(user_input)

    # Fuzzy match
    matched_key, score = fuzzy_match(user_input, normalized_lookup)

    is_suggestion = detect_place_suggestion(user_input)


    # N·∫øu follow-up nh∆∞ng ƒë√£ c√≥ topic ‚Üí ti·∫øp t·ª•c
    if intent == "follow_up" and st.session_state.topic:
        matched_key = st.session_state.topic

    # N·∫øu match t·ªët ‚Üí d√πng d·ªØ li·ªáu offline

    if is_suggestion:
        st.session_state.topic = None
            # L·∫•y 2 ƒë·ªãa ƒëi·ªÉm ƒë·∫ßu ti√™n ƒë√∫ng t·ª´ d·ªØ li·ªáu
        top_places = list(tourism_data.keys())[:2]

    # Gh√©p n·ªôi dung th·∫≠t t·ª´ file
        places_text = ""
        for p in top_places:
            places_text += f"\n### {p}\n{tourism_data[p]}\n"
            
        prompt = f"""
        B·∫°n l√† h∆∞·ªõng d·∫´n vi√™n du l·ªãch T√¢y Ninh.

        Ng∆∞·ªùi d√πng mu·ªën g·ª£i √Ω ƒë·ªãa ƒëi·ªÉm.

        D·ª±a tr√™n d·ªØ li·ªáu:
        ---
        {places_text}
        ---

        Ch·ªâ ƒë∆∞·ª£c tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu b√™n tr√™n.
        Kh√¥ng ƒë∆∞·ª£c b·ªãa ra ƒë·ªãa danh m·ªõi, ho·∫°t ƒë·ªông m·ªõi ho·∫∑c th√¥ng tin ngo√†i d·ªØ li·ªáu.
    
        H√£y m√¥ t·∫£ t·ª´ng ƒë·ªãa ƒëi·ªÉm c√≥ ƒë·ªÅ m·ª•c r√µ r√†ng:
        - Gi·ªõi thi·ªáu ng·∫Øn g·ªçn
        - Ho·∫°t ƒë·ªông th√∫ v·ªã
        - Th·ªùi gian n√™n ƒëi

        Tr·∫£ l·ªùi th·∫≠t t·ª± nhi√™n v√† th√¢n thi·ªán, ch√≠nh x√°c v√† ch·ªâ tr·∫£ l·ªùi b·∫±ng ti·∫øng vi·ªát.
        """

    elif matched_key:
        st.session_state.topic = matched_key
        context = tourism_data.get(matched_key, "").strip()

        prompt = f"""
        B·∫°n l√† h∆∞·ªõng d·∫´n vi√™n du l·ªãch T√¢y Ninh.
        Ng∆∞·ªùi d√πng h·ªèi: "{user_input}"

        ƒê√¢y l√† th√¥ng tin v·ªÅ ƒë·ªãa ƒëi·ªÉm **{matched_key}**:
        ---
        {context}
        ---

        Ch·ªâ ƒë∆∞·ª£c tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu b√™n tr√™n.
        Kh√¥ng ƒë∆∞·ª£c b·ªãa ra ƒë·ªãa danh m·ªõi, ho·∫°t ƒë·ªông m·ªõi ho·∫∑c th√¥ng tin ngo√†i d·ªØ li·ªáu.
        
        H√£y tr·∫£ l·ªùi t·ª± nhi√™n, th√¢n thi·ªán v√† ch√≠nh x√°c d·ª±a tr√™n d·ªØ li·ªáu v√† tr·∫£ l·ªùi b·∫±ng ti·∫øng vi·ªát.
        ƒê·ªìng th·ªùi cung c·∫•p:
        - T∆∞ v·∫•n c√°c ho·∫°t ƒë·ªông th√∫ v·ªã
        - th·ªùi gian n√™n ƒëi
        """
        
    # Kh√¥ng match ‚Üí h·ªèi to√†n b·ªô d·ªØ li·ªáu
    else:
        st.session_state.topic = None
        prompt = f"""
        B·∫°n l√† h∆∞·ªõng d·∫´n vi√™n du l·ªãch T√¢y Ninh.
        D·ªØ li·ªáu du l·ªãch:
        ---
        {places_text}
        ---

        C√¢u h·ªèi: "{user_input}"
        
        Ch·ªâ ƒë∆∞·ª£c tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu b√™n tr√™n.
        Kh√¥ng ƒë∆∞·ª£c b·ªãa ra ƒë·ªãa danh m·ªõi, ho·∫°t ƒë·ªông m·ªõi ho·∫∑c th√¥ng tin ngo√†i d·ªØ li·ªáu.

        H√£y xin l·ªói v√† tr·∫£ l·ªùi l√† n∆°i n√†y s·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t sau v√† g·ª£i √Ω:
        - Gi·ªõi thi·ªáu ng·∫Øn
        - Ho·∫°t ƒë·ªông th√∫ v·ªã
        - Th·ªùi gian n√™n ƒëi
        """

    # ======================================
    # ü§ñ G·ªåI OLLAMA
    # ======================================

    placeholder = st.chat_message("assistant").empty()
    placeholder.markdown("‚è≥ *ƒêang t·∫°o c√¢u tr·∫£ l·ªùi...*")

    full_reply = ""

    try:
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": "qwen2:1.5b",
                "prompt": prompt,
                "stream": True,
                "options": {"temperature": 0.4},
            },
            stream=True
        )

        for line in response.iter_lines():
            if line:
                data = json.loads(line)
                if "response" in data:
                    full_reply += data["response"]
                    placeholder.markdown(full_reply + "‚ñå")

    except Exception as e:
        full_reply = f"‚ö†Ô∏è L·ªói khi k·∫øt n·ªëi AI: {e}"

    # ======================================
    # üîó TH√äM LINK GOOGLE MAPS
    # ======================================
    if st.session_state.topic:
        google_query = st.session_state.topic.replace(" ", "+")
        maps_url = f"https://www.google.com/maps/search/?api=1&query={google_query}+tay+ninh"
        full_reply += f"\n\nüìç **Google Maps:** [Xem b·∫£n ƒë·ªì]({maps_url})"

    # C·∫≠p nh·∫≠t tr·∫£ l·ªùi
    placeholder.markdown(full_reply.strip())
    st.session_state.messages.append({"role": "assistant", "content": full_reply.strip()})

    # ======================================
    # üçú G·ª¢I √ù QU√ÅN ƒÇN
    # ======================================
    if st.session_state.topic:
        key = st.session_state.topic.lower()
        if key in food_spots:
            with st.expander("üçú G·ª£i √Ω qu√°n ƒÉn g·∫ßn ƒë√¢y"):
                for name, note in food_spots[key]:
                    st.markdown(f"- **{name}** ‚Äî _{note}_")

    # ======================================
    # üñº HI·ªÇN TH·ªä ·∫¢NH
    # ======================================
    if st.session_state.topic and st.session_state.topic in images:
        arr = images[st.session_state.topic]
        if arr:
            with st.expander(f"üì∏ H√¨nh ·∫£nh v·ªÅ {st.session_state.topic.title()}"):
                for img in arr:
                    st.image(img, use_container_width=True)
